{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79c5ec7c",
   "metadata": {},
   "source": [
    "# 1. Extract features of training and test images using a pre-trained ResNet50 model (50 points)\n",
    "Please print the size of extracted features, e.g., training features: 1400 * d, test features: 400 *d."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc24bcc1",
   "metadata": {},
   "source": [
    "### Dataset Preparation:\n",
    "\n",
    "Define labeled (for train) and unlabeled (for test) dataset classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e9f0084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Tuple\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.utils\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51d6e599",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogHeartLabeledDataset(ImageFolder):\n",
    "\n",
    "    #extend\n",
    "    def __init__(self, data_root: str) -> None:\n",
    "        self.transformation = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Resize((224, 224)),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "        ])\n",
    "        super().__init__(root=data_root, transform=self.transformation)\n",
    "        self.data_root: str = data_root\n",
    "\n",
    "        self.filepaths: List[str] = [path for path, _ in self.samples]\n",
    "        self.filenames: List[str] = [path.split('/')[-1] for path in self.filepaths]\n",
    "        self.labels: List[int] = [label for _, label in self.samples]\n",
    "\n",
    "    #extend\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int, str]:\n",
    "        tensor: torch.Tensor; label: int\n",
    "        tensor, label = super().__getitem__(idx)\n",
    "        tensor = tensor.half()\n",
    "        filename: str = self.filenames[idx]\n",
    "        return tensor, label, filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f64e54fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogHearUnlabeledDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_root: str) -> None:\n",
    "        self.data_root: str = data_root\n",
    "        self.transformation = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Resize((224, 224)),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "        ])\n",
    "        self.filenames: List[str] = os.listdir(self.data_root)\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def __getitem__(self, idx) -> Tuple[torch.Tensor, str]:\n",
    "        filename: str = self.filenames[idx]\n",
    "        image: Image = Image.open(os.path.join(self.data_root, filename))\n",
    "        if image.mode == 'RGBA':\n",
    "            image = image.convert('RGB')\n",
    "        tensor: torch.Tensor = self.transformation(image).half()\n",
    "        return tensor, filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0d1c2e",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "\n",
    "Define `FeatureExtractor` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21092611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import resnet50, ResNet50_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "594313d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        resnet = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        # get the feature extractor blocks, drop last FC layer\n",
    "        self.__extractor = nn.Sequential(\n",
    "            *list(resnet.children())[:-1], \n",
    "            nn.Flatten(start_dim=1, end_dim=-1)\n",
    "        ).half()\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        assert input.ndim == 4\n",
    "        assert input.shape[1:] == (3, 224, 224)\n",
    "        return self.__extractor(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521eaa6e",
   "metadata": {},
   "source": [
    "Call the `FeatureExtractor` on train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a229b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose device\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# Instantiate train data\n",
    "train_dataset = DogHeartLabeledDataset(data_root='Dog_heart/Train')\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Instantiate a feature extractor\n",
    "feature_extractor = FeatureExtractor().to(device)\n",
    "\n",
    "# Apply the feature extractor on train data\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=True,\n",
    ")\n",
    "input_tensors: List[torch.Tensor] = []\n",
    "label_tensors: List[torch.Tensor] = []\n",
    "for input_tensor, label_tensor, _ in train_dataloader:\n",
    "    input_tensors.append(input_tensor.to(device=device, dtype=torch.half))\n",
    "    label_tensors.append(label_tensor.to(device=device))\n",
    "\n",
    "input_tensor: torch.Tensor = torch.cat(input_tensors)\n",
    "label_tensor: torch.Tensor = torch.cat(label_tensors)\n",
    "\n",
    "with torch.no_grad():\n",
    "    feature_extractor.eval()\n",
    "    train_features: torch.Tensor = feature_extractor(input=input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd33acb1",
   "metadata": {},
   "source": [
    "Print the shape of output features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce6187ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1400, 2048])\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e3e068",
   "metadata": {},
   "source": [
    "# 2. Call SVM and kNN from scikit-learn and train the extracted deep features, respectively (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb066a7",
   "metadata": {},
   "source": [
    "Define the class `Predict` that accepts one feature extractor and one classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49095773",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        feature_extractor: nn.Module,\n",
    "        classifier: BaseEstimator,\n",
    "        device: torch.device = torch.device('cuda')\n",
    "    ):\n",
    "        self.feature_extractor = feature_extractor.to(device)\n",
    "        self.classifier = classifier\n",
    "        self.device = device\n",
    "\n",
    "    def fit(self, train_dataset: Dataset) -> None:\n",
    "        train_dataloader = DataLoader(\n",
    "            dataset=train_dataset, \n",
    "            batch_size=32, \n",
    "            shuffle=True,\n",
    "        )\n",
    "        input_tensors: List[torch.Tensor] = []\n",
    "        label_tensors: List[torch.Tensor] = []\n",
    "        for input_tensor, label_tensor, _ in train_dataloader:\n",
    "            input_tensors.append(input_tensor.to(device=self.device, dtype=torch.half))\n",
    "            label_tensors.append(label_tensor.to(device=self.device))\n",
    "\n",
    "        input_tensor: torch.Tensor = torch.cat(input_tensors)\n",
    "        label_tensor: torch.Tensor = torch.cat(label_tensors)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.feature_extractor.eval()\n",
    "            train_features: torch.Tensor = self.feature_extractor(input=input_tensor)\n",
    "\n",
    "        self.classifier.fit(\n",
    "            X=train_features.detach().cpu().numpy(), \n",
    "            y=label_tensor.cpu().numpy()\n",
    "        )\n",
    "\n",
    "    def predict(self, test_dataset: Dataset) -> pd.DataFrame:\n",
    "        test_dataloader = DataLoader(\n",
    "            dataset=test_dataset, \n",
    "            batch_size=32, \n",
    "            shuffle=False\n",
    "        )\n",
    "        input_tensors: List[torch.Tensor] = []\n",
    "        filenames: List[str] = []\n",
    "        for input_tensor, fnames in test_dataloader:\n",
    "            input_tensors.append(input_tensor.to(device=self.device, dtype=torch.half))\n",
    "            filenames.extend(fnames)\n",
    "\n",
    "        input_tensor: torch.Tensor = torch.cat(input_tensors)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.feature_extractor.eval()\n",
    "            test_features: torch.Tensor = self.feature_extractor(input=input_tensor)\n",
    "\n",
    "        predicted_labels: np.ndarray = self.classifier.predict(\n",
    "            X=test_features.detach().cpu().numpy(),\n",
    "        )\n",
    "        prediction_table = pd.DataFrame(\n",
    "            data={'image': filenames, 'label': predicted_labels}\n",
    "        )\n",
    "        prediction_table.to_csv(\n",
    "            f'{self.classifier.__class__.__name__}_'\n",
    "            f'{self.feature_extractor.__class__.__name__}.csv', \n",
    "            header=False, \n",
    "            index=False,\n",
    "        )\n",
    "        return prediction_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d695070a",
   "metadata": {},
   "source": [
    "Extract the features and use them to train 2 models: `SVM` and `kNN`, the predictions on test data are output as `.csv` files in the working directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68704a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "train_dataset = DogHeartLabeledDataset(data_root='Dog_heart/Train')\n",
    "test_dataset = DogHearUnlabeledDataset(data_root='Dog_heart/Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76fd9af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1967.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1804.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1988.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1657.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1810.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1955.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1969.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1835.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1821.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1809.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        image  label\n",
       "0    1967.png      0\n",
       "1    1804.png      2\n",
       "2    1988.png      1\n",
       "3    1657.png      0\n",
       "4    1810.png      0\n",
       "..        ...    ...\n",
       "395  1955.png      1\n",
       "396  1969.png      0\n",
       "397  1835.png      1\n",
       "398  1821.png      0\n",
       "399  1809.png      1\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "resnet_svm = Predictor(\n",
    "    feature_extractor=FeatureExtractor(), \n",
    "    classifier=SVC(), \n",
    "    device=device, \n",
    ")\n",
    "resnet_svm.fit(train_dataset)\n",
    "resnet_svm.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13f81862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1967.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1804.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1988.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1657.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1810.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1955.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1969.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1835.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1821.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1809.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        image  label\n",
       "0    1967.png      1\n",
       "1    1804.png      1\n",
       "2    1988.png      1\n",
       "3    1657.png      1\n",
       "4    1810.png      0\n",
       "..        ...    ...\n",
       "395  1955.png      0\n",
       "396  1969.png      0\n",
       "397  1835.png      0\n",
       "398  1821.png      0\n",
       "399  1809.png      0\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kNN with k=5\n",
    "resnet_5nn = Predictor(\n",
    "    feature_extractor=FeatureExtractor(), \n",
    "    classifier=KNeighborsClassifier(n_neighbors=5),\n",
    "    device=device, \n",
    ")\n",
    "resnet_5nn.fit(train_dataset)\n",
    "resnet_5nn.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd101cf",
   "metadata": {},
   "source": [
    "# 3. Report the accuracy using Dog_X_ray_classfication_accuracy software, please attach the results image here (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7631278",
   "metadata": {},
   "source": [
    "SVM Classifier:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/hiepdang-ml/dnn_assignment5/master/SVC_FeatureExtractor.png\" alt=\"SVMPredictionImage\" style=\"width:40%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6608d1e4",
   "metadata": {},
   "source": [
    "5-NN Classifier:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/hiepdang-ml/dnn_assignment5/master/KNeighborsClassifier_FeatureExtractor.png\" alt=\"KNNPredictionImage\" style=\"width:40%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06236b15",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
